{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversational Search Retrieval Augmented Generation\n",
    "\n",
    "In this notebook you will implement the following steps:\n",
    "\n",
    "- **Answer selection + evaluation**: Implement a *search-based* conversation framework evaluation framework to evaluate conversation topics made up of conversation turns.\n",
    "- **Answer ranking**: Implement a *re-ranking method* to sort the initial search results. Evaluate the re-ranked results.\n",
    "- **Conversation memory**: Implement a conversational context modeling method to keep track of the conversation state. \n",
    "\n",
    "Submission dates:\n",
    "- **20 October**: first stage retrieval + conversation memory + evaluation\n",
    "- **15 November**: re-ranking with LLM + evaluation\n",
    "- **15 December**: answer generation + evaluation\n",
    "\n",
    "## Test bed and conversation topics\n",
    "The TREC CAST corpus (http://www.treccast.ai/) for Conversational Search is indexed in this cluster and available to be searched behind an OpenSearch API.\n",
    "\n",
    "The queries and the relevance judgments are available through class `ConvSearchEvaluation`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/anna/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True, 'shards_acknowledged': True}\n",
      "\n",
      "----------------------------------------------------------------------------------- INDEX SETTINGS\n",
      "{'kwiz': {'settings': {'index': {'creation_date': '1728153198145',\n",
      "                                 'knn': 'true',\n",
      "                                 'number_of_replicas': '0',\n",
      "                                 'number_of_shards': '1',\n",
      "                                 'provided_name': 'kwiz',\n",
      "                                 'refresh_interval': '-1',\n",
      "                                 'similarity': {'default': {'lambda': '0.7',\n",
      "                                                            'type': 'LMJelinekMercer'}},\n",
      "                                 'uuid': 'qkpQ7pcwS7iT1IOTsfwRNg',\n",
      "                                 'version': {'created': '135238227'}}}}}\n",
      "\n",
      "----------------------------------------------------------------------------------- INDEX MAPPINGS\n",
      "{'kwiz': {'mappings': {'properties': {'collection': {'type': 'keyword'},\n",
      "                                      'contents': {'index_options': 'freqs',\n",
      "                                                   'similarity': 'BM25',\n",
      "                                                   'store': True,\n",
      "                                                   'term_vector': 'yes',\n",
      "                                                   'type': 'text'},\n",
      "                                      'doc': {'type': 'keyword'},\n",
      "                                      'sentence_embedding': {'model_id': 'model_kwiz',\n",
      "                                                             'type': 'knn_vector'}}}}}\n",
      "\n",
      "----------------------------------------------------------------------------------- INDEX #DOCs\n",
      "{'count': 23596, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}\n"
     ]
    }
   ],
   "source": [
    "import TRECCASTeval as trec\n",
    "import numpy as np\n",
    "import pprint\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import OpenSearchSimpleAPI as osearch\n",
    "import bm25s\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "\n",
    "test_bed = trec.ConvSearchEvaluation()\n",
    "\n",
    "chosen_topic= 77\n",
    "conversation = []\n",
    "topics = {}\n",
    "for topic in test_bed.train_topics:\n",
    "    conv_id = topic['number']\n",
    "    if conv_id not in (1, 2, 4, 7, 15, 17, 18, 22, 23, 24, 25, 27, 30):\n",
    "        continue\n",
    "    for turn in topic['turn']:\n",
    "        turn_id = turn['number']\n",
    "        utterance = turn['raw_utterance']\n",
    "        topic_turn_id = '%d_%d' % (conv_id, turn_id)\n",
    "        topics[topic_turn_id] = utterance\n",
    "        if conv_id == chosen_topic :\n",
    "            conversation.append({\"conv_id\" : conv_id, \"turn_id\" : turn_id, \"utterance\" : utterance})\n",
    "\n",
    "\n",
    "for topic in test_bed.test_topics:\n",
    "    conv_id = topic['number']\n",
    "\n",
    "    if conv_id not in (31, 32, 33, 34, 37, 40, 49, 50, 54, 56, 58, 59, 61, 67, 68, 69, 75, 77, 78, 79):\n",
    "        continue\n",
    "    for turn in topic['turn']:\n",
    "        turn_id = turn['number']\n",
    "        utterance = turn['raw_utterance']\n",
    "        topic_turn_id = '%d_%d' % (conv_id, turn_id)\n",
    "        topics[topic_turn_id] = utterance\n",
    "        if conv_id == chosen_topic :\n",
    "            conversation.append({\"conv_id\" : conv_id, \"turn_id\" : turn_id, \"utterance\" : utterance})\n",
    "\n",
    "\n",
    "opensearch = osearch.OSsimpleAPI()\n",
    "\n",
    "numdocs = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  turn                                           query  \\\n",
      "0    1    What's the difference between soup and stew?   \n",
      "1    2                               Is chilli a stew?   \n",
      "2    3                              How about goulash?   \n",
      "3    4                What are popular ones in France?   \n",
      "4    5                          How is cassoulet made?   \n",
      "5    6    Tell me about feijoada and its significance.   \n",
      "6    7  How is it similar or different from cassoulet?   \n",
      "7    8                          Tell about Bigos stew.   \n",
      "8    9                            Why is it important?   \n",
      "9   10              What is the history of Irish stew?   \n",
      "\n",
      "                                   expanded_query  \\\n",
      "0    What's the difference between soup and stew?   \n",
      "1                               Is chilli a stew?   \n",
      "2                              How about goulash?   \n",
      "3                What are popular ones in France?   \n",
      "4                          How is cassoulet made?   \n",
      "5    Tell me about feijoada and its significance.   \n",
      "6  How is it similar or different from cassoulet?   \n",
      "7                          Tell about Bigos stew.   \n",
      "8                            Why is it important?   \n",
      "9              What is the history of Irish stew?   \n",
      "\n",
      "                                        top passages  \\\n",
      "0  [What's the difference between a soup and a st...   \n",
      "1  [Fricasse â tiny sandwich with tuna, harissa...   \n",
      "2  [How to cook the perfect goulash. Goulash is a...   \n",
      "3  [What are the most popular sports in France? C...   \n",
      "4  [The region once known as the province of Lang...   \n",
      "5  [I want to do the Company Secretary course fro...   \n",
      "6  [The phrases hard to lose electrons and easy t...   \n",
      "7  [A national dish of Poland, bigos is a traditi...   \n",
      "8  [GDP per capita is viewed to be important as i...   \n",
      "9  [Irish Beef Stew [slow cooker]. [Slow cooker v...   \n",
      "\n",
      "                                                 _id  \n",
      "0      [MARCO_3831856, MARCO_3712923, MARCO_3070255]  \n",
      "1      [MARCO_2801272, MARCO_3318351, MARCO_3318357]  \n",
      "2  [MARCO_1595926, CAR_60759f5845c44489d3f277c92f...  \n",
      "3  [MARCO_3581032, CAR_4c169e88f8453e8dea2b89d9f1...  \n",
      "4  [CAR_66eff27699239eb298881ab9f16759580ff73208,...  \n",
      "5      [MARCO_6083641, MARCO_8827796, MARCO_8344507]  \n",
      "6  [MARCO_6005525, CAR_66eff27699239eb298881ab9f1...  \n",
      "7        [MARCO_228565, MARCO_228568, MARCO_4418424]  \n",
      "8       [MARCO_673867, MARCO_5028938, MARCO_3823042]  \n",
      "9       [MARCO_571975, MARCO_7907228, MARCO_3712925]  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def BM_retrieval(k):\n",
    "    #metrics_df = pd.DataFrame(columns=['turn', 'query', '_id'])\n",
    "    BM25data = []\n",
    "    bm25_doc_ids = []\n",
    "    for element in conversation :\n",
    "        topic = str(chosen_topic)\n",
    "        turn = str(element['turn_id'])\n",
    "        utterance = topic + '_' + turn\n",
    "   \n",
    "        query = topics[utterance]\n",
    "        opensearch_results = opensearch.search_body(query, numDocs = k)\n",
    "        best_docs = []\n",
    "        best_passages = []\n",
    "        content_to_id = {}  \n",
    "        for index, row in opensearch_results.iterrows():\n",
    "            doc_id = row['_id']\n",
    "            doc_body = opensearch.get_doc_body(doc_id)\n",
    "            #new_row = {'turn': utterance, 'query': element['utterance'], '_id': doc_id}\n",
    "            #metrics_df = pd.concat([metrics_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            best_passages.append(doc_body)\n",
    "            best_docs.append(doc_id)\n",
    "            content_to_id[doc_body] = doc_id  \n",
    "        bm25_doc_ids.append([content_to_id[doc] for doc in best_passages if doc in content_to_id])\n",
    "   \n",
    "            \n",
    "        BM25data.append({'turn': turn, 'query': element[\"utterance\"], \"expanded_query\" : query,  'top passages': best_passages, '_id': best_docs})\n",
    "\n",
    "    df = pd.DataFrame(BM25data)\n",
    "   \n",
    "    return df\n",
    "\n",
    "print(BM_retrieval(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m         scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(scores, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m scores[:k]\n\u001b[0;32m---> 64\u001b[0m bm25_results \u001b[38;5;241m=\u001b[39m BM_retrieval(\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m#print(bm25_results)\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m#print('-------------------------------------------------------------------------------------')\u001b[39;00m\n\u001b[1;32m     71\u001b[0m reranked_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mturn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_id\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[2], line 17\u001b[0m, in \u001b[0;36mBM_retrieval\u001b[0;34m(k)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m opensearch_results\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     16\u001b[0m     doc_id \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 17\u001b[0m     doc_body \u001b[38;5;241m=\u001b[39m opensearch\u001b[38;5;241m.\u001b[39mget_doc_body(doc_id)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m#new_row = {'turn': utterance, 'query': element['utterance'], '_id': doc_id}\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m#metrics_df = pd.concat([metrics_df, pd.DataFrame([new_row])], ignore_index=True)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     best_passages\u001b[38;5;241m.\u001b[39mappend(doc_body)\n",
      "File \u001b[0;32m~/Desktop/ri_project/OpenSearchSimpleAPI.py:93\u001b[0m, in \u001b[0;36mOSsimpleAPI.get_doc_body\u001b[0;34m(self, doc_id)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_doc_body\u001b[39m(\u001b[38;5;28mself\u001b[39m, doc_id):\n\u001b[0;32m---> 93\u001b[0m     aa \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_name, \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mdoc_id)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_source\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontents\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m aa\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/opensearchpy/client/utils.py:176\u001b[0m, in \u001b[0;36mquery_params.<locals>._wrapper.<locals>._wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m             params[p] \u001b[38;5;241m=\u001b[39m _escape(v)\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, params\u001b[38;5;241m=\u001b[39mparams, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/opensearchpy/client/__init__.py:1360\u001b[0m, in \u001b[0;36mOpenSearch.get\u001b[0;34m(self, index, id, params, headers)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m SKIP_IN_PATH:\n\u001b[1;32m   1358\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty value passed for a required argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1360\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransport\u001b[38;5;241m.\u001b[39mperform_request(\n\u001b[1;32m   1361\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m, _make_path(index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_doc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mid\u001b[39m), params\u001b[38;5;241m=\u001b[39mparams, headers\u001b[38;5;241m=\u001b[39mheaders\n\u001b[1;32m   1362\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/opensearchpy/transport.py:416\u001b[0m, in \u001b[0;36mTransport.perform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[1;32m    413\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_connection()\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     status, headers_response, data \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mperform_request(\n\u001b[1;32m    417\u001b[0m         method,\n\u001b[1;32m    418\u001b[0m         url,\n\u001b[1;32m    419\u001b[0m         params,\n\u001b[1;32m    420\u001b[0m         body,\n\u001b[1;32m    421\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    422\u001b[0m         ignore\u001b[38;5;241m=\u001b[39mignore,\n\u001b[1;32m    423\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    424\u001b[0m     )\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;66;03m# Lowercase all the header names for consistency in accessing them.\u001b[39;00m\n\u001b[1;32m    427\u001b[0m     headers_response \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    428\u001b[0m         header\u001b[38;5;241m.\u001b[39mlower(): value \u001b[38;5;28;01mfor\u001b[39;00m header, value \u001b[38;5;129;01min\u001b[39;00m headers_response\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    429\u001b[0m     }\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/opensearchpy/connection/http_urllib3.py:280\u001b[0m, in \u001b[0;36mUrllib3HttpConnection.perform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[1;32m    276\u001b[0m         request_headers\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_auth(method, full_url, body))\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mrequest_start()\n\u001b[0;32m--> 280\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    281\u001b[0m     method, url, body, retries\u001b[38;5;241m=\u001b[39mRetry(\u001b[38;5;28;01mFalse\u001b[39;00m), headers\u001b[38;5;241m=\u001b[39mrequest_headers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw\n\u001b[1;32m    282\u001b[0m )\n\u001b[1;32m    283\u001b[0m duration \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start\n\u001b[1;32m    284\u001b[0m raw_data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    790\u001b[0m     conn,\n\u001b[1;32m    791\u001b[0m     method,\n\u001b[1;32m    792\u001b[0m     url,\n\u001b[1;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[1;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[1;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[1;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[1;32m    802\u001b[0m )\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/urllib3/connection.py:464\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 464\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    467\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/http/client.py:1423\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1422\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1423\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1425\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# LMDRetriever\n",
    "class LMDRetriever:\n",
    "    def __init__(self, opensearch, corpus_ids):\n",
    "        self.opensearch = opensearch\n",
    "        self.corpus_ids = corpus_ids\n",
    "        self.corpus_length = 0\n",
    "        self.doc_count = len(corpus_ids)\n",
    "        self.index = self.build_index()\n",
    "        self.collection_frequency = self.build_collection_frequency()\n",
    "        self.mu = self.calculate_mu()\n",
    "    \n",
    "    def calculate_mu(self):\n",
    "        avg_doc_length = self.corpus_length / self.doc_count\n",
    "        return 0.1 * avg_doc_length\n",
    "\n",
    "    def build_index(self):\n",
    "        index = {}\n",
    "        for doc_id in self.corpus_ids:\n",
    "            term_vectors = self.opensearch.doc_term_vectors(doc_id)\n",
    "            if term_vectors:\n",
    "                terms = term_vectors[3]\n",
    "                for term, stats in terms.items():\n",
    "                    if term not in index:\n",
    "                        index[term] = {}\n",
    "                    index[term][doc_id] = stats[0]\n",
    "                    self.corpus_length += stats[0]\n",
    "        return index\n",
    "\n",
    "    def build_collection_frequency(self):\n",
    "        collection_frequency = {}\n",
    "        for doc_id in self.corpus_ids:\n",
    "            term_vectors = self.opensearch.doc_term_vectors(doc_id)\n",
    "            if term_vectors:\n",
    "                terms = term_vectors[3]\n",
    "                for term, stats in terms.items():\n",
    "                    if term not in collection_frequency:\n",
    "                        collection_frequency[term] = 0\n",
    "                    collection_frequency[term] += stats[2]\n",
    "        return collection_frequency\n",
    "\n",
    "    def score(self, query, doc_id):\n",
    "        score = 1.0\n",
    "        term_vectors = self.opensearch.doc_term_vectors(doc_id)\n",
    "        if term_vectors:\n",
    "            terms = term_vectors[3]\n",
    "            doc_length = sum([stats[0] for stats in terms.values()])\n",
    "            for term in query.split():\n",
    "                tf = terms.get(term, [0])[0]\n",
    "                cf = self.collection_frequency.get(term, 0)\n",
    "                p_ml = cf / self.corpus_length\n",
    "                p_lmd = (tf + self.mu * p_ml) / (doc_length + self.mu)\n",
    "                if p_lmd > 0:\n",
    "                    score *= p_lmd\n",
    "        return score\n",
    "\n",
    "    def retrieve(self, query, k):\n",
    "        scores = []\n",
    "        for doc_id in self.corpus_ids:\n",
    "            score = self.score(query, doc_id)\n",
    "            scores.append((doc_id, score))\n",
    "        scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "        return scores[:k]\n",
    "\n",
    "bm25_results = BM_retrieval(100)\n",
    "\n",
    "#print(bm25_results)\n",
    "\n",
    "#print('-------------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "reranked_df = pd.DataFrame(columns=[\"turn\", \"query\", \"_id\"])\n",
    "\n",
    "\n",
    "for index, row in bm25_results.iterrows():\n",
    "   \n",
    "    bm25_doc_ids = row[\"_id\"] \n",
    "    turn = row[\"turn\"]\n",
    "    query = row[\"expanded_query\"]\n",
    "\n",
    "    # Créer une instance de LMDRetriever avec les doc_ids récupérés\n",
    "    lmd_retriever = LMDRetriever(opensearch=opensearch, corpus_ids=bm25_doc_ids)\n",
    "\n",
    "    # Reranking avec la méthode retrieve\n",
    "    reranked_results = lmd_retriever.retrieve(query, k=100)\n",
    "\n",
    "    # Extraire les passages du reranking\n",
    "    top_N_passages = [doc_id for doc_id, score in reranked_results]\n",
    "\n",
    "    # Créer un DataFrame temporaire pour la nouvelle ligne\n",
    "    new_row = pd.DataFrame({\n",
    "        \"turn\": [turn],\n",
    "        \"query\": [query],\n",
    "        \"_id\": [top_N_passages]\n",
    "    })\n",
    "\n",
    "\n",
    "    # Utiliser pd.concat pour ajouter la nouvelle ligne au DataFrame final\n",
    "    reranked_df = pd.concat([reranked_df, new_row], ignore_index=True)\n",
    "\n",
    "# Afficher le DataFrame final\n",
    "print(reranked_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LMD\n",
      "Turn: 77_1\n",
      "P@10: 0.6, Recall: 0.6153846153846154, AP: 0.21890349531082884, NDCG@5: 0.1599902354470432\n",
      "\n",
      "Turn: 77_2\n",
      "P@10: 0.0, Recall: 0.4, AP: 0.009639830508474575, NDCG@5: 0.0\n",
      "\n",
      "Turn: 77_3\n",
      "P@10: 0.3, Recall: 0.7435897435897436, AP: 0.2410340073882552, NDCG@5: 0.10157051007554901\n",
      "\n",
      "Turn: 77_4\n",
      "P@10: 0.1, Recall: 0.20833333333333334, AP: 0.02203193303734692, NDCG@5: 0.25326335410655304\n",
      "\n",
      "Turn: 77_5\n",
      "P@10: 0.6, Recall: 0.9444444444444444, AP: 0.4116411106384749, NDCG@5: 0.25064969555809496\n",
      "\n",
      "Turn: 77_6\n",
      "P@10: 0.2, Recall: 0.125, AP: 0.03187957875457875, NDCG@5: 0.18322608909137006\n",
      "\n",
      "Turn: 77_7\n",
      "P@10: 0.2, Recall: 0.22857142857142856, AP: 0.03654396991052007, NDCG@5: 0.10907458963273321\n",
      "\n",
      "Turn: 77_8\n",
      "P@10: 0.2, Recall: 0.84375, AP: 0.20964821424602653, NDCG@5: 0.0\n",
      "\n",
      "Turn: 77_9\n",
      "P@10: 0, Recall: 0, AP: 0, NDCG@5: 0\n",
      "\n",
      "Turn: 77_10\n",
      "P@10: 0, Recall: 0, AP: 0, NDCG@5: 0\n",
      "\n",
      "['77_1', '77_2', '77_3', '77_4', '77_5', '77_6', '77_7', '77_8', '77_9', '77_10'] [0.21890349531082884, 0.009639830508474575, 0.2410340073882552, 0.02203193303734692, 0.4116411106384749, 0.03187957875457875, 0.03654396991052007, 0.20964821424602653, 0, 0] [0.1599902354470432, 0.0, 0.10157051007554901, 0.25326335410655304, 0.25064969555809496, 0.18322608909137006, 0.10907458963273321, 0.0, 0, 0] [0.6, 0.0, 0.3, 0.1, 0.6, 0.2, 0.2, 0.2, 0, 0] [0.6153846153846154, 0.4, 0.7435897435897436, 0.20833333333333334, 0.9444444444444444, 0.125, 0.22857142857142856, 0.84375, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "turns = []\n",
    "LMD_ap_values = []\n",
    "LMD_ndcg_values = []\n",
    "LMD_precision_values = []\n",
    "LMD_recall_values = []\n",
    "\n",
    "print(\"LMD\")\n",
    "\n",
    "for index, row in reranked_df.iterrows():\n",
    "    try:\n",
    "    \n",
    "        turn = f\"77_{row['turn']}\"  \n",
    "        query = row['query']\n",
    "        docs = row['_id']  \n",
    "\n",
    "        result_df = pd.DataFrame({\"_id\": docs})\n",
    "\n",
    "        p10, recall, ap, ndcg5 = test_bed.eval(result_df, turn)\n",
    "        turns.append(turn)\n",
    "        LMD_ap_values.append(ap)\n",
    "        LMD_ndcg_values.append(ndcg5)\n",
    "        LMD_precision_values.append(p10)\n",
    "        LMD_recall_values.append(recall)\n",
    "\n",
    "        print(f\"Turn: {turn}\")\n",
    "        \n",
    "    \n",
    "        print(f\"P@10: {p10}, Recall: {recall}, AP: {ap}, NDCG@5: {ndcg5}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "  \n",
    "        print(f\"Erreur sur le tour {turn}: {e}\")\n",
    "        break  \n",
    "\n",
    "print(turns,LMD_ap_values,LMD_ndcg_values,LMD_precision_values, LMD_recall_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "filtered_turns = []\n",
    "filtered_ap_values = []\n",
    "filtered_ndcg_values = []\n",
    "filtered_precision_values = []\n",
    "filtered_recall_values = []\n",
    "\n",
    "for i in range(len(turns)):\n",
    "\n",
    "    if LMD_ap_values[i] != 0 or LMD_ndcg_values[i] != 0:\n",
    "        filtered_turns.append(turns[i])\n",
    "        filtered_ap_values.append(LMD_ap_values[i])\n",
    "        filtered_ndcg_values.append(LMD_ndcg_values[i])\n",
    "\n",
    " \n",
    "    if LMD_precision_values[i] != 0 or LMD_recall_values[i] != 0:\n",
    "        filtered_precision_values.append(LMD_precision_values[i])\n",
    "        filtered_recall_values.append(LMD_recall_values[i])\n",
    "\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(filtered_turns, filtered_ap_values, marker='o', label='AP', linestyle='-')\n",
    "plt.plot(filtered_turns, filtered_ndcg_values, marker='x', label='NDCG@5', linestyle='-')\n",
    "plt.title(\"Evolution of AP and NCDG5 for each turn\")\n",
    "plt.xlabel(\"Turns\")\n",
    "plt.ylabel(\"Scores\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(filtered_recall_values, filtered_precision_values, marker='o', label='Precision-Recall')\n",
    "plt.title(\"Precision-Recall\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
