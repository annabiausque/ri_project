{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81cc73a1-7f5b-4c2a-8b55-060c877054db",
   "metadata": {},
   "source": [
    "#### Uncomment the nltk.download if you haven't downloaded it yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e61a5dc-3005-4382-b643-38e3070facc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import TRECCASTeval as trec\n",
    "import numpy as np\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import OpenSearchSimpleAPI as osearch\n",
    "import pprint as pp\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "531e7674-4e73-4524-af32-15e13ce87806",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "test_bed = trec.ConvSearchEvaluation()\n",
    "\n",
    "# Initialize stop words and stemmer\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8c5efa-5162-4242-bb26-523c409345c1",
   "metadata": {},
   "source": [
    "### Preprocess text will tokenize the text \n",
    "This function takes in raw text (usually conversational utterances) and performs the following:\n",
    "\n",
    "- Converts the text to lowercase.\n",
    "- Removes non-alphanumeric characters (punctuation, symbols).\n",
    "- Removes common stopwords using the NLTK stopwords list.\n",
    "- Stems each word using the Porter stemmer to reduce words to their base forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c25ca386-b496-4c83-b787-8d8a1ac7f083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    text = ' '.join([stemmer.stem(word) for word in text.split()])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4703e9c-5acd-4d3a-9cd1-e78409ebaea3",
   "metadata": {},
   "source": [
    "### Training and Test Data Processing\n",
    "\n",
    "Here, we iterate over the training and testing topics provided by the test_bed. We filter out some conversation IDs based on predefined criteria, and then process each utterance in the conversation using our preprocess_text function. The preprocessed utterances are accumulated over turns of the conversation to simulate a growing context.\n",
    "\n",
    "Key Variables:\n",
    "- **previous_query_tokenized**: Keeps track of the concatenated previous utterances to simulate a conversation history.\n",
    "- **topics**: Stores each turn's preprocessed utterances, indexed by a combination of the conversation ID and turn number.\n",
    "\n",
    "(Printing of the queries is optional and used mostly for debug purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "756a20e7-9880-4b38-86ee-369422629edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_turn_id</th>\n",
       "      <th>dummy</th>\n",
       "      <th>docid</th>\n",
       "      <th>rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31_1</td>\n",
       "      <td>Q0</td>\n",
       "      <td>CAR_116d829c4c800c2fc70f11692fec5e8c7e975250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31_1</td>\n",
       "      <td>Q0</td>\n",
       "      <td>CAR_1463f964653c5c9f614a0a88d26b175e4a8120f1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31_1</td>\n",
       "      <td>Q0</td>\n",
       "      <td>CAR_172e16e89ea3d5546e53384a27c3be299bcfe968</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31_1</td>\n",
       "      <td>Q0</td>\n",
       "      <td>CAR_1c93ef499a0c2856c4a857b0cb4720c380dda476</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31_1</td>\n",
       "      <td>Q0</td>\n",
       "      <td>CAR_2174ad0aa50712ff24035c23f59a3c2b43267650</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29345</th>\n",
       "      <td>79_9</td>\n",
       "      <td>Q0</td>\n",
       "      <td>MARCO_8795229</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29346</th>\n",
       "      <td>79_9</td>\n",
       "      <td>Q0</td>\n",
       "      <td>MARCO_8795231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29347</th>\n",
       "      <td>79_9</td>\n",
       "      <td>Q0</td>\n",
       "      <td>MARCO_8795233</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29348</th>\n",
       "      <td>79_9</td>\n",
       "      <td>Q0</td>\n",
       "      <td>MARCO_8795236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29349</th>\n",
       "      <td>79_9</td>\n",
       "      <td>Q0</td>\n",
       "      <td>MARCO_8795237</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29350 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      topic_turn_id dummy                                         docid  rel\n",
       "0              31_1    Q0  CAR_116d829c4c800c2fc70f11692fec5e8c7e975250    0\n",
       "1              31_1    Q0  CAR_1463f964653c5c9f614a0a88d26b175e4a8120f1    1\n",
       "2              31_1    Q0  CAR_172e16e89ea3d5546e53384a27c3be299bcfe968    2\n",
       "3              31_1    Q0  CAR_1c93ef499a0c2856c4a857b0cb4720c380dda476    0\n",
       "4              31_1    Q0  CAR_2174ad0aa50712ff24035c23f59a3c2b43267650    3\n",
       "...             ...   ...                                           ...  ...\n",
       "29345          79_9    Q0                                 MARCO_8795229    0\n",
       "29346          79_9    Q0                                 MARCO_8795231    0\n",
       "29347          79_9    Q0                                 MARCO_8795233    0\n",
       "29348          79_9    Q0                                 MARCO_8795236    0\n",
       "29349          79_9    Q0                                 MARCO_8795237    3\n",
       "\n",
       "[29350 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change visualization of the tokenized queries\n",
    "print_queries = False\n",
    "\n",
    "chosen_topic= 77\n",
    "conversation = []\n",
    "\n",
    "print(\"========================================== Training conversations =====\") if print_queries else 0\n",
    "topics = {}\n",
    "for topic in test_bed.train_topics:\n",
    "    conv_id = topic['number']\n",
    "\n",
    "    if conv_id not in (1, 2, 4, 7, 15, 17,18,22,23,24,25,27,30):\n",
    "        continue\n",
    "\n",
    "    print() if print_queries else 0\n",
    "    print(conv_id, \"  \", topic['title']) if print_queries else 0\n",
    "\n",
    "    previous_query_tokenized = ''\n",
    "    for turn in topic['turn']:\n",
    "        turn_id = turn['number']\n",
    "        utterance = turn['raw_utterance']\n",
    "        updated_utterance = previous_query_tokenized + utterance\n",
    "        previous_query_tokenized += preprocess_text(utterance) + ' '\n",
    "        topic_turn_id = '%d_%d'% (conv_id, turn_id)\n",
    "        \n",
    "        print(topic_turn_id, updated_utterance) if print_queries else 0\n",
    "        topics[topic_turn_id] = updated_utterance\n",
    "        if conv_id == chosen_topic :\n",
    "            conversation.append({\"conv_id\" : conv_id, \"turn_id\" : turn_id, \"utterance\" : utterance})\n",
    "\n",
    "\n",
    "print() if print_queries else 0\n",
    "print(\"========================================== Test conversations =====\") if print_queries else 0\n",
    "for topic in test_bed.test_topics:\n",
    "    conv_id = topic['number']\n",
    "\n",
    "    if conv_id not in (31, 32, 33, 34, 37, 40, 49, 50, 54, 56, 58, 59, 61, 67, 68, 69, 75, 77, 78, 79):\n",
    "        continue\n",
    "\n",
    "\n",
    "    #print(conv_id, \"  \", topic['title'])\n",
    "\n",
    "    previous_query_tokenized = ''\n",
    "    for turn in topic['turn']:\n",
    "        turn_id = turn['number']\n",
    "        utterance = turn['raw_utterance']\n",
    "        updated_utterance = previous_query_tokenized + utterance\n",
    "        previous_query_tokenized += preprocess_text(utterance) + ' '\n",
    "        topic_turn_id = '%d_%d'% (conv_id, turn_id)\n",
    "        \n",
    "        print(topic_turn_id, updated_utterance) if print_queries else 0\n",
    "        topics[topic_turn_id] = updated_utterance\n",
    "        if conv_id == chosen_topic :\n",
    "            conversation.append({\"conv_id\" : conv_id, \"turn_id\" : turn_id, \"utterance\" : utterance})\n",
    "\n",
    "\n",
    "test_bed.test_relevance_judgments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a984bf-7053-468e-b368-5c43cac38007",
   "metadata": {},
   "source": [
    "# OpenSearch implementation\n",
    "\n",
    "### Setup\n",
    "\n",
    "The OpenSearch API is initialized, confirming index creation with the following settings:\n",
    "\n",
    "**Index name**: kwiz   \n",
    "**Similarity**: BM25 for text ranking and LM Jelinek-Mercer for smoothing (λ=0.7)   \n",
    "**Shards**: 1 shard, no replicas   \n",
    "**Documents**: 23,596 documents indexed   \n",
    "**k-NN enabled**: Sentence embeddings available for vector-based queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29a1aa08-3ae1-4d39-930b-6edc5e39726d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True, 'shards_acknowledged': True}\n",
      "\n",
      "----------------------------------------------------------------------------------- INDEX SETTINGS\n",
      "{'kwiz': {'settings': {'index': {'creation_date': '1728153198145',\n",
      "                                 'knn': 'true',\n",
      "                                 'number_of_replicas': '0',\n",
      "                                 'number_of_shards': '1',\n",
      "                                 'provided_name': 'kwiz',\n",
      "                                 'refresh_interval': '-1',\n",
      "                                 'similarity': {'default': {'lambda': '0.7',\n",
      "                                                            'type': 'LMJelinekMercer'}},\n",
      "                                 'uuid': 'qkpQ7pcwS7iT1IOTsfwRNg',\n",
      "                                 'version': {'created': '135238227'}}}}}\n",
      "\n",
      "----------------------------------------------------------------------------------- INDEX MAPPINGS\n",
      "{'kwiz': {'mappings': {'properties': {'collection': {'type': 'keyword'},\n",
      "                                      'contents': {'index_options': 'freqs',\n",
      "                                                   'similarity': 'BM25',\n",
      "                                                   'store': True,\n",
      "                                                   'term_vector': 'yes',\n",
      "                                                   'type': 'text'},\n",
      "                                      'doc': {'type': 'keyword'},\n",
      "                                      'sentence_embedding': {'model_id': 'model_kwiz',\n",
      "                                                             'type': 'knn_vector'}}}}}\n",
      "\n",
      "----------------------------------------------------------------------------------- INDEX #DOCs\n",
      "{'count': 23596, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}\n"
     ]
    }
   ],
   "source": [
    "opensearch = osearch.OSsimpleAPI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103b7b3f-04d8-4a06-9a3e-8b913ee21469",
   "metadata": {},
   "source": [
    "We conduct a test search using a single preprocessed query (61_7) to retrieve the top 100 documents from the OpenSearch API. This helps verify if the query is functioning correctly and if we receive results as expected.\n",
    "\n",
    "The results of the OpenSearch query are printed to ensure that the API returns valid documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "716af03c-c508-41b8-8da8-70e1d40198e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   _index _type                                           _id     _score  \\\n",
      "0    kwiz  _doc  CAR_54ddfb93ad52e7e7bdf960f5cd3164f683eb757b  42.747547   \n",
      "1    kwiz  _doc  CAR_4b18b521b30a9d32d2c2852b05a5fffce336ca4e  39.716260   \n",
      "2    kwiz  _doc  CAR_db3beebe1d9e72b74daeec818f076a1e6a794b9d  36.619880   \n",
      "3    kwiz  _doc                                 MARCO_3765773  36.438580   \n",
      "4    kwiz  _doc  CAR_56f5109e7dcc45e4bcf50cbc789a3fff94ab1575  35.619743   \n",
      "..    ...   ...                                           ...        ...   \n",
      "95   kwiz  _doc                                 MARCO_6139465  25.450195   \n",
      "96   kwiz  _doc  CAR_613140b2eab12517d1da86bb42d2688934a3d4e1  25.309765   \n",
      "97   kwiz  _doc                                 MARCO_8019905  25.259228   \n",
      "98   kwiz  _doc  CAR_d8c0ddb5a2cec36eec0eb592c845665ee060e847  25.202800   \n",
      "99   kwiz  _doc                                 MARCO_8344507  25.190685   \n",
      "\n",
      "                                     _source.contents  \\\n",
      "0   The Justice League is a fictional group of sup...   \n",
      "1   The team is an assemblage of superheroes who j...   \n",
      "2   In Infinite Crisis #7 (June 2006), the formati...   \n",
      "3   ~ Superman deciding to form a team called the ...   \n",
      "4   The Justice League Dark, or JLD, is a fictiona...   \n",
      "..                                                ...   \n",
      "95  Sorting type: |. Enemies of the Justice League...   \n",
      "96  The Elongated Man (Randolph \"Ralph\" Dibny) is ...   \n",
      "97  At Comic-Con in July, Warner Bros. announced t...   \n",
      "98  In June 2013, Goyer was hired to write the seq...   \n",
      "99  Answer Model to develop your own responses. 1 ...   \n",
      "\n",
      "                                     _source.doc _source.collection  \n",
      "0   CAR_54ddfb93ad52e7e7bdf960f5cd3164f683eb757b          wikipedia  \n",
      "1   CAR_4b18b521b30a9d32d2c2852b05a5fffce336ca4e          wikipedia  \n",
      "2   CAR_db3beebe1d9e72b74daeec818f076a1e6a794b9d          wikipedia  \n",
      "3                                  MARCO_3765773            msmarco  \n",
      "4   CAR_56f5109e7dcc45e4bcf50cbc789a3fff94ab1575          wikipedia  \n",
      "..                                           ...                ...  \n",
      "95                                 MARCO_6139465            msmarco  \n",
      "96  CAR_613140b2eab12517d1da86bb42d2688934a3d4e1          wikipedia  \n",
      "97                                 MARCO_8019905            msmarco  \n",
      "98  CAR_d8c0ddb5a2cec36eec0eb592c845665ee060e847          wikipedia  \n",
      "99                                 MARCO_8344507            msmarco  \n",
      "\n",
      "[100 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "numdocs = 100\n",
    "\n",
    "test_query = topics['61_7']\n",
    "\n",
    "opensearch_results = opensearch.search_body(test_query, numDocs = numdocs)\n",
    "print(opensearch_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc96bdd8-414b-426e-b10e-54d1efbcc6b6",
   "metadata": {},
   "source": [
    "## BM25-based Retrieval\n",
    "\n",
    "This section performs document retrieval using the BM25 ranking algorithm for all queries in topics.   \n",
    "For each query, the top 3 documents are retrieved from OpenSearch and from each of those documents, we extract the body (passage) and it's ID.   \n",
    "The results are stored in a Pandas DataFrame for easier visualization and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614cdc08-b129-4091-8f23-677976e422c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "61",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m     query \u001b[38;5;241m=\u001b[39m topics[topic]\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(query)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(BM_retrieval(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m61\u001b[39m))\n",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m, in \u001b[0;36mBM_retrieval\u001b[0;34m(k, topic)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mBM_retrieval\u001b[39m(k,topic):\n\u001b[1;32m      2\u001b[0m     BM25data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m     query \u001b[38;5;241m=\u001b[39m topics[topic]\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(query)\n",
      "\u001b[0;31mKeyError\u001b[0m: 61"
     ]
    }
   ],
   "source": [
    "\n",
    "def BM_retrieval(k,topic):\n",
    "    BM25data = []\n",
    "    for element in conversation :\n",
    "        topic = str(element['conv_id'])\n",
    "        turn = str(element['turn_id'])\n",
    "        utterance = topic + '_' + turn\n",
    "        print(utterance)\n",
    "    test_query = topics[utterance]\n",
    "    query = topics[topic]\n",
    "    print(query)\n",
    "    opensearch_results = opensearch.search_body(query, numDocs = k)\n",
    "    best_docs = []\n",
    "    best_passages = []\n",
    "    for index, row in opensearch_results.iterrows():\n",
    "        doc_id = row['_id']\n",
    "        doc_body = opensearch.get_doc_body(doc_id)\n",
    "        best_passages.append(doc_body)\n",
    "        best_docs.append(doc_id)\n",
    "    BM25data.append({'turn': topic, 'query': query, 'top passages': best_passages, 'doc ids': best_docs})\n",
    "    \n",
    "    df = pd.DataFrame(BM25data)\n",
    "    print(df)\n",
    "\n",
    "print(BM_retrieval(3,\"61\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f42cf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "p10, recall, ap, ndcg5 = test_bed.eval(df, '77_1')\n",
    "\n",
    "print(p10,recall, ap, ndcg5 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
