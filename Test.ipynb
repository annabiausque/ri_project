{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81cc73a1-7f5b-4c2a-8b55-060c877054db",
   "metadata": {},
   "source": [
    "#### Uncomment the nltk.download if you haven't downloaded it yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e61a5dc-3005-4382-b643-38e3070facc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import TRECCASTeval as trec\n",
    "import numpy as np\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import OpenSearchSimpleAPI as osearch\n",
    "import pprint as pp\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "531e7674-4e73-4524-af32-15e13ce87806",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "test_bed = trec.ConvSearchEvaluation()\n",
    "\n",
    "# Initialize stop words and stemmer\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8c5efa-5162-4242-bb26-523c409345c1",
   "metadata": {},
   "source": [
    "### Preprocess text will tokenize the text \n",
    "This function takes in raw text (usually conversational utterances) and performs the following:\n",
    "\n",
    "- Converts the text to lowercase.\n",
    "- Removes non-alphanumeric characters (punctuation, symbols).\n",
    "- Removes common stopwords using the NLTK stopwords list.\n",
    "- Stems each word using the Porter stemmer to reduce words to their base forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c25ca386-b496-4c83-b787-8d8a1ac7f083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    text = ' '.join([stemmer.stem(word) for word in text.split()])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4703e9c-5acd-4d3a-9cd1-e78409ebaea3",
   "metadata": {},
   "source": [
    "### Training and Test Data Processing\n",
    "\n",
    "Here, we iterate over the training and testing topics provided by the test_bed. We filter out some conversation IDs based on predefined criteria, and then process each utterance in the conversation using our preprocess_text function. The preprocessed utterances are accumulated over turns of the conversation to simulate a growing context.\n",
    "\n",
    "Key Variables:\n",
    "- **previous_query_tokenized**: Keeps track of the concatenated previous utterances to simulate a conversation history.\n",
    "- **topics**: Stores each turn's preprocessed utterances, indexed by a combination of the conversation ID and turn number.\n",
    "\n",
    "(Printing of the queries is optional and used mostly for debug purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "756a20e7-9880-4b38-86ee-369422629edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'conv_id': 77, 'turn_id': 1, 'utterance': \"What's the difference between soup and stew?\"}, {'conv_id': 77, 'turn_id': 2, 'utterance': 'Is chilli a stew?'}, {'conv_id': 77, 'turn_id': 3, 'utterance': 'How about goulash?'}, {'conv_id': 77, 'turn_id': 4, 'utterance': 'What are popular ones in France?'}, {'conv_id': 77, 'turn_id': 5, 'utterance': 'How is cassoulet made?'}, {'conv_id': 77, 'turn_id': 6, 'utterance': 'Tell me about feijoada and its significance.'}, {'conv_id': 77, 'turn_id': 7, 'utterance': 'How is it similar or different from cassoulet?'}, {'conv_id': 77, 'turn_id': 8, 'utterance': 'Tell about Bigos stew.'}, {'conv_id': 77, 'turn_id': 9, 'utterance': 'Why is it important?'}, {'conv_id': 77, 'turn_id': 10, 'utterance': 'What is the history of Irish stew?'}]\n"
     ]
    }
   ],
   "source": [
    "# Change visualization of the tokenized queries\n",
    "print_queries = False\n",
    "\n",
    "chosen_topic= 77\n",
    "conversation = []\n",
    "\n",
    "print(\"========================================== Training conversations =====\") if print_queries else 0\n",
    "topics = {}\n",
    "for topic in test_bed.train_topics:\n",
    "    conv_id = topic['number']\n",
    "\n",
    "    if conv_id not in (1, 2, 4, 7, 15, 17,18,22,23,24,25,27,30):\n",
    "        continue\n",
    "\n",
    "    print() if print_queries else 0\n",
    "    print(conv_id, \"  \", topic['title']) if print_queries else 0\n",
    "\n",
    "    previous_query_tokenized = ''\n",
    "    for turn in topic['turn']:\n",
    "        turn_id = turn['number']\n",
    "        utterance = turn['raw_utterance']\n",
    "        updated_utterance = previous_query_tokenized + utterance\n",
    "        previous_query_tokenized += preprocess_text(utterance) + ' '\n",
    "        topic_turn_id = '%d_%d'% (conv_id, turn_id)\n",
    "        \n",
    "        print(topic_turn_id, updated_utterance) if print_queries else 0\n",
    "        topics[topic_turn_id] = updated_utterance\n",
    "        if conv_id == chosen_topic :\n",
    "            conversation.append({\"conv_id\" : conv_id, \"turn_id\" : turn_id, \"utterance\" : utterance})\n",
    "\n",
    "\n",
    "print() if print_queries else 0\n",
    "print(\"========================================== Test conversations =====\") if print_queries else 0\n",
    "for topic in test_bed.test_topics:\n",
    "    conv_id = topic['number']\n",
    "\n",
    "    if conv_id not in (31, 32, 33, 34, 37, 40, 49, 50, 54, 56, 58, 59, 61, 67, 68, 69, 75, 77, 78, 79):\n",
    "        continue\n",
    "\n",
    "\n",
    "    #print(conv_id, \"  \", topic['title'])\n",
    "\n",
    "    previous_query_tokenized = ''\n",
    "    for turn in topic['turn']:\n",
    "        turn_id = turn['number']\n",
    "        utterance = turn['raw_utterance']\n",
    "        updated_utterance = previous_query_tokenized + utterance\n",
    "        previous_query_tokenized += preprocess_text(utterance) + ' '\n",
    "        topic_turn_id = '%d_%d'% (conv_id, turn_id)\n",
    "        \n",
    "        print(topic_turn_id, updated_utterance) if print_queries else 0\n",
    "        topics[topic_turn_id] = updated_utterance\n",
    "        if conv_id == chosen_topic :\n",
    "            conversation.append({\"conv_id\" : conv_id, \"turn_id\" : turn_id, \"utterance\" : utterance})\n",
    "\n",
    "\n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a984bf-7053-468e-b368-5c43cac38007",
   "metadata": {},
   "source": [
    "# OpenSearch implementation\n",
    "\n",
    "### Setup\n",
    "\n",
    "The OpenSearch API is initialized, confirming index creation with the following settings:\n",
    "\n",
    "**Index name**: kwiz   \n",
    "**Similarity**: BM25 for text ranking and LM Jelinek-Mercer for smoothing (Î»=0.7)   \n",
    "**Shards**: 1 shard, no replicas   \n",
    "**Documents**: 23,596 documents indexed   \n",
    "**k-NN enabled**: Sentence embeddings available for vector-based queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29a1aa08-3ae1-4d39-930b-6edc5e39726d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True, 'shards_acknowledged': True}\n",
      "\n",
      "----------------------------------------------------------------------------------- INDEX SETTINGS\n",
      "{'kwiz': {'settings': {'index': {'creation_date': '1728153198145',\n",
      "                                 'knn': 'true',\n",
      "                                 'number_of_replicas': '0',\n",
      "                                 'number_of_shards': '1',\n",
      "                                 'provided_name': 'kwiz',\n",
      "                                 'refresh_interval': '-1',\n",
      "                                 'similarity': {'default': {'lambda': '0.7',\n",
      "                                                            'type': 'LMJelinekMercer'}},\n",
      "                                 'uuid': 'qkpQ7pcwS7iT1IOTsfwRNg',\n",
      "                                 'version': {'created': '135238227'}}}}}\n",
      "\n",
      "----------------------------------------------------------------------------------- INDEX MAPPINGS\n",
      "{'kwiz': {'mappings': {'properties': {'collection': {'type': 'keyword'},\n",
      "                                      'contents': {'index_options': 'freqs',\n",
      "                                                   'similarity': 'BM25',\n",
      "                                                   'store': True,\n",
      "                                                   'term_vector': 'yes',\n",
      "                                                   'type': 'text'},\n",
      "                                      'doc': {'type': 'keyword'},\n",
      "                                      'sentence_embedding': {'model_id': 'model_kwiz',\n",
      "                                                             'type': 'knn_vector'}}}}}\n",
      "\n",
      "----------------------------------------------------------------------------------- INDEX #DOCs\n",
      "{'count': 23596, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}\n"
     ]
    }
   ],
   "source": [
    "opensearch = osearch.OSsimpleAPI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103b7b3f-04d8-4a06-9a3e-8b913ee21469",
   "metadata": {},
   "source": [
    "We conduct a test search using a single preprocessed query (61_7) to retrieve the top 100 documents from the OpenSearch API. This helps verify if the query is functioning correctly and if we receive results as expected.\n",
    "\n",
    "The results of the OpenSearch query are printed to ensure that the API returns valid documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "716af03c-c508-41b8-8da8-70e1d40198e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   _index _type                                           _id     _score  \\\n",
      "0    kwiz  _doc  CAR_54ddfb93ad52e7e7bdf960f5cd3164f683eb757b  42.747547   \n",
      "1    kwiz  _doc  CAR_4b18b521b30a9d32d2c2852b05a5fffce336ca4e  39.716260   \n",
      "2    kwiz  _doc  CAR_db3beebe1d9e72b74daeec818f076a1e6a794b9d  36.619880   \n",
      "3    kwiz  _doc                                 MARCO_3765773  36.438580   \n",
      "4    kwiz  _doc  CAR_56f5109e7dcc45e4bcf50cbc789a3fff94ab1575  35.619743   \n",
      "..    ...   ...                                           ...        ...   \n",
      "95   kwiz  _doc                                 MARCO_6139465  25.450195   \n",
      "96   kwiz  _doc  CAR_613140b2eab12517d1da86bb42d2688934a3d4e1  25.309765   \n",
      "97   kwiz  _doc                                 MARCO_8019905  25.259228   \n",
      "98   kwiz  _doc  CAR_d8c0ddb5a2cec36eec0eb592c845665ee060e847  25.202800   \n",
      "99   kwiz  _doc                                 MARCO_8344507  25.190685   \n",
      "\n",
      "                                     _source.contents  \\\n",
      "0   The Justice League is a fictional group of sup...   \n",
      "1   The team is an assemblage of superheroes who j...   \n",
      "2   In Infinite Crisis #7 (June 2006), the formati...   \n",
      "3   ~ Superman deciding to form a team called the ...   \n",
      "4   The Justice League Dark, or JLD, is a fictiona...   \n",
      "..                                                ...   \n",
      "95  Sorting type: |. Enemies of the Justice League...   \n",
      "96  The Elongated Man (Randolph \"Ralph\" Dibny) is ...   \n",
      "97  At Comic-Con in July, Warner Bros. announced t...   \n",
      "98  In June 2013, Goyer was hired to write the seq...   \n",
      "99  Answer Model to develop your own responses. 1 ...   \n",
      "\n",
      "                                     _source.doc _source.collection  \n",
      "0   CAR_54ddfb93ad52e7e7bdf960f5cd3164f683eb757b          wikipedia  \n",
      "1   CAR_4b18b521b30a9d32d2c2852b05a5fffce336ca4e          wikipedia  \n",
      "2   CAR_db3beebe1d9e72b74daeec818f076a1e6a794b9d          wikipedia  \n",
      "3                                  MARCO_3765773            msmarco  \n",
      "4   CAR_56f5109e7dcc45e4bcf50cbc789a3fff94ab1575          wikipedia  \n",
      "..                                           ...                ...  \n",
      "95                                 MARCO_6139465            msmarco  \n",
      "96  CAR_613140b2eab12517d1da86bb42d2688934a3d4e1          wikipedia  \n",
      "97                                 MARCO_8019905            msmarco  \n",
      "98  CAR_d8c0ddb5a2cec36eec0eb592c845665ee060e847          wikipedia  \n",
      "99                                 MARCO_8344507            msmarco  \n",
      "\n",
      "[100 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "numdocs = 100\n",
    "\n",
    "test_query = topics['61_7']\n",
    "\n",
    "opensearch_results = opensearch.search_body(test_query, numDocs = numdocs)\n",
    "print(opensearch_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc96bdd8-414b-426e-b10e-54d1efbcc6b6",
   "metadata": {},
   "source": [
    "## BM25-based Retrieval\n",
    "\n",
    "This section performs document retrieval using the BM25 ranking algorithm for all queries in topics.   \n",
    "For each query, the top 3 documents are retrieved from OpenSearch and from each of those documents, we extract the body (passage) and it's ID.   \n",
    "The results are stored in a Pandas DataFrame for easier visualization and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "614cdc08-b129-4091-8f23-677976e422c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  turn                                           query  \\\n",
      "0    1    What's the difference between soup and stew?   \n",
      "1    2                               Is chilli a stew?   \n",
      "2    3                              How about goulash?   \n",
      "3    4                What are popular ones in France?   \n",
      "4    5                          How is cassoulet made?   \n",
      "5    6    Tell me about feijoada and its significance.   \n",
      "6    7  How is it similar or different from cassoulet?   \n",
      "7    8                          Tell about Bigos stew.   \n",
      "8    9                            Why is it important?   \n",
      "9   10              What is the history of Irish stew?   \n",
      "\n",
      "                                        top passages  \\\n",
      "0  [What's the difference between a soup and a st...   \n",
      "1  [Specifically, I've always had some confusion ...   \n",
      "2  [1 Stew is more of a meat and vegetables dish ...   \n",
      "3  [Goulash is a rustic stew or soup made made wi...   \n",
      "4  [Goulash is a rustic stew or soup made with be...   \n",
      "5  [Specifically, I've always had some confusion ...   \n",
      "6  [Goulash is a rustic stew or soup made with be...   \n",
      "7  [Specifically, I've always had some confusion ...   \n",
      "8  [Specifically, I've always had some confusion ...   \n",
      "9  [Specifically, I've always had some confusion ...   \n",
      "\n",
      "                                             doc ids  \n",
      "0      [MARCO_3831856, MARCO_3712923, MARCO_3070255]  \n",
      "1      [MARCO_3712923, MARCO_4533564, MARCO_4533561]  \n",
      "2  [MARCO_4948690, MARCO_1469735, CAR_d0dbb5da9f3...  \n",
      "3       [MARCO_954770, MARCO_1469735, MARCO_4948690]  \n",
      "4       [MARCO_8594804, MARCO_954770, MARCO_1469735]  \n",
      "5       [MARCO_3712923, MARCO_8594804, MARCO_954770]  \n",
      "6  [MARCO_8594804, CAR_f3d89bb386f24d75540a4e5cce...  \n",
      "7  [MARCO_3712923, MARCO_1899971, CAR_f3d89bb386f...  \n",
      "8      [MARCO_3712923, MARCO_8594804, MARCO_1899971]  \n",
      "9      [MARCO_3712923, MARCO_1469735, MARCO_1899971]  \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def BM_retrieval(k):\n",
    "    BM25data = []\n",
    "    for element in conversation :\n",
    "        topic = str(chosen_topic)\n",
    "        turn = str(element['turn_id'])\n",
    "        utterance = topic + '_' + turn\n",
    "   \n",
    "        query = topics[utterance]\n",
    "\n",
    "        opensearch_results = opensearch.search_body(query, numDocs = k)\n",
    "        best_docs = []\n",
    "        best_passages = []\n",
    "        for index, row in opensearch_results.iterrows():\n",
    "            doc_id = row['_id']\n",
    "            doc_body = opensearch.get_doc_body(doc_id)\n",
    "            best_passages.append(doc_body)\n",
    "            best_docs.append(doc_id)\n",
    "        BM25data.append({'turn': turn, 'query': element[\"utterance\"], 'top passages': best_passages, 'doc ids': best_docs})\n",
    "        \n",
    "    df = pd.DataFrame(BM25data)\n",
    "    print(df)\n",
    "\n",
    "print(BM_retrieval(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f42cf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "p10, recall, ap, ndcg5 = test_bed.eval(df, '77_1')\n",
    "\n",
    "print(p10,recall, ap, ndcg5 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
