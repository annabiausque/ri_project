{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44650c1c-d142-4fa6-bfe9-783517e0dc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rick/anaconda3/envs/nlp-cv-ir/lib/python3.9/site-packages/transformers/deepspeed.py:24: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from bertviz import model_view, head_view\n",
    "from transformers import *\n",
    "\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "# Get the interactive Tools for Matplotlib\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eca5aa6f-877d-4af9-8325-202cd9c2a238",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55d07011-a508-4b60-9d52-e7b97511817c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "406b3ad2-0314-42fc-8832-e816125dd66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/rick/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.44.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/rick/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/vocab.txt\n",
      "loading file tokenizer.json from cache at /home/rick/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/rick/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/rick/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.44.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "/home/rick/anaconda3/envs/nlp-cv-ir/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/rick/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_attentions\": true,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.44.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/rick/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/model.safetensors\n",
      "A pretrained model of type `BertModel` contains parameters that have been renamed internally (a few are listed below but more are present in the model):\n",
      "* `bert.embeddings.LayerNorm.gamma` -> `bert.embeddings.LayerNorm.weight`\n",
      "* `bert.encoder.layer.0.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.0.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.1.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.1.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.10.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.10.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.11.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.11.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.2.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.2.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.3.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.3.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.4.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.4.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.5.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.5.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.6.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.6.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.7.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.7.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.8.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.8.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.9.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.encoder.layer.9.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `cls.predictions.transform.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
      "* `bert.embeddings.LayerNorm.beta` -> `bert.embeddings.LayerNorm.bias`\n",
      "* `bert.encoder.layer.0.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.0.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.1.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.1.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.10.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.10.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.11.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.11.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.2.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.2.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.3.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.3.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.4.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.4.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.5.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.5.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.6.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.6.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.7.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.7.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.8.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.8.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.9.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `bert.encoder.layer.9.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "* `cls.predictions.transform.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
      "If you are using a model from the Hub, consider submitting a PR to adjust these weights and help future users.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "config = AutoConfig.from_pretrained(model_path,  output_hidden_states=True, output_attentions=True)  \n",
    "model = AutoModel.from_pretrained(model_path, config=config).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3259f0c2-ab89-43bc-bff6-b79c03a1abec",
   "metadata": {},
   "source": [
    "# Creation of dummy (query,doc) pairs -> Replace by the actual (query, doc) pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe685422-11c5-4e50-901f-7e6f774364aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Sample queries\n",
    "query_a = \"Is throat cancer treatable nowadays?\"\n",
    "query_b = \"How to deal with hypothermia?\"\n",
    "\n",
    "# Sample documents\n",
    "sentence_a = \"58-year-old woman with hypertension\"\n",
    "sentence_b = \"BACKGROUND : Longitudinal studies hypertension\"\n",
    "\n",
    "number_documents = 3600\n",
    "\n",
    "# Create dummy (query, document) pairs\n",
    "# TODO: replace by your own (query, document) pairs\n",
    "query_pairs = [(random.choice([query_a, query_b]), \n",
    "           random.choice([sentence_a, sentence_b])) for i in range(number_documents)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4fa806-a516-4eac-86d7-f039e35d4ec4",
   "metadata": {},
   "source": [
    "## CLS Embedding Extraction in Batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "743c4240-eb79-4b39-a87f-84a9f3635a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "    \n",
    "def extract_cls(query_pairs, embeddings, batch_size=32):\n",
    "\n",
    "    # Iterate over all documents, in batches of size <batch_size>\n",
    "    for batch_idx in range(0, len(query_pairs), batch_size):\n",
    "\n",
    "        # Get the current batch of samples\n",
    "        batch_data = query_pairs[batch_idx:batch_idx + batch_size]\n",
    "\n",
    "        inputs = tokenizer.batch_encode_plus(batch_data, \n",
    "                                       return_tensors='pt',  # pytorch tensors\n",
    "                                       add_special_tokens=True,  # Add CLS and SEP tokens\n",
    "                                       max_length = 512, # Max sequence length\n",
    "                                       truncation = True, # Truncate if sequences exceed the Max Sequence length\n",
    "                                       padding = True) # Add padding to forward sequences with different lengths\n",
    "        \n",
    "        # Forward the batch of (query, doc) sequences\n",
    "        with torch.no_grad():\n",
    "            inputs.to(device)\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        # Get the CLS embeddings for each pair query, document\n",
    "        batch_cls = outputs['hidden_states'][-1][:,0,:]\n",
    "        \n",
    "        # L2-Normalize CLS embeddings. Embeddings norm will be 1.\n",
    "        batch_cls = torch.nn.functional.normalize(batch_cls, p=2, dim=1)\n",
    "        \n",
    "        # Store the extracted CLS embeddings from the batch on the memory-mapped ndarray\n",
    "        embeddings[batch_idx:batch_idx + batch_size] = batch_cls.cpu()\n",
    "        \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73969563-e0bc-4304-9611-9a08f8c13fcf",
   "metadata": {},
   "source": [
    "The code below will extract CLS embeddings for all query_pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8676e10d-93a7-4d3a-80df-79dd899936ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3600, 768)\n"
     ]
    }
   ],
   "source": [
    "# Numpy ndarray that will store (in RAM) the CLS embeddings of each (query, doc) pair\n",
    "embeddings = np.zeros((len(query_pairs), 768))\n",
    "\n",
    "embeddings = extract_cls(query_pairs, embeddings=embeddings, batch_size=32)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63af13e6-99cf-4256-a553-a2f08c88d4cd",
   "metadata": {},
   "source": [
    "## If you're running into memory issues - Put Numpy Arrays on disk\n",
    "\n",
    "The code below extracts CLS embeddings for all query_pairs and stores them on disk, using persistent Numpy ndarrays. The difference is that they won't be stored on your computer RAM. After creating the array as shown below, the fact that they are on disk is abstracted, and you can use them as you would do with standard numpy arrays.\n",
    "\n",
    "Since it writes to disk, it will be slower than the first option, but the amount of RAM needed will be dramatically reduced.\n",
    "\n",
    "Reference: https://numpy.org/doc/stable/reference/generated/numpy.memmap.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05e944fa-794f-4022-bb05-f228a7bd9698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3600, 768)\n"
     ]
    }
   ],
   "source": [
    "filename = \"cls_embeddings.dat\"\n",
    "\n",
    "# Create a memory-mapped numpy array. The array is stored on disk, not on RAM\n",
    "# The shape argument must match (total number query-doc pairs, CLS embedding size)\n",
    "embeddings_persistent = np.memmap(filename, dtype='float32', mode='w+', shape=(len(query_pairs), 768))\n",
    "\n",
    "embeddings_persistent = extract_cls(query_pairs, embeddings=embeddings_persistent, batch_size=32)\n",
    "print(embeddings_persistent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d89724-b6b1-47c2-8f34-7b3b1ea73fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
