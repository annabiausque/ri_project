{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversational Search Retrieval Augmented Generation\n",
    "\n",
    "#### Uncomment the nltk.download if you haven't downloaded it yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/anna/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import TRECCASTeval as trec\n",
    "import numpy as np\n",
    "import pprint\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import OpenSearchSimpleAPI as osearch\n",
    "import bm25s\n",
    "import pandas as pd\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "\n",
    "test_bed = trec.ConvSearchEvaluation()\n",
    "\n",
    "# Initialize stop words and stemmer\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess text will tokenize the text \n",
    "This function takes in raw text (usually conversational utterances) and performs the following:\n",
    "\n",
    "- Converts the text to lowercase.\n",
    "- Removes non-alphanumeric characters (punctuation, symbols).\n",
    "- Removes common stopwords using the NLTK stopwords list.\n",
    "- Stems each word using the Porter stemmer to reduce words to their base forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    text = ' '.join([stemmer.stem(word) for word in text.split()])\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Test Data Processing\n",
    "\n",
    "Here, we iterate over the training and testing topics provided by the test_bed. We filter out some conversation IDs based on predefined criteria, and then process each utterance in the conversation using our preprocess_text function. The preprocessed utterances are accumulated over turns of the conversation to simulate a growing context.\n",
    "\n",
    "Key Variables:\n",
    "- **previous_query_tokenized**: Keeps track of the concatenated previous utterances to simulate a conversation history.\n",
    "- **topics**: Stores each turn's preprocessed utterances, indexed by a combination of the conversation ID and turn number.\n",
    "\n",
    "(Printing of the queries is optional and used mostly for debug purposes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True, 'shards_acknowledged': True}\n",
      "\n",
      "----------------------------------------------------------------------------------- INDEX SETTINGS\n",
      "{'kwiz': {'settings': {'index': {'creation_date': '1728153198145',\n",
      "                                 'knn': 'true',\n",
      "                                 'number_of_replicas': '0',\n",
      "                                 'number_of_shards': '1',\n",
      "                                 'provided_name': 'kwiz',\n",
      "                                 'refresh_interval': '-1',\n",
      "                                 'similarity': {'default': {'lambda': '0.7',\n",
      "                                                            'type': 'LMJelinekMercer'}},\n",
      "                                 'uuid': 'qkpQ7pcwS7iT1IOTsfwRNg',\n",
      "                                 'version': {'created': '135238227'}}}}}\n",
      "\n",
      "----------------------------------------------------------------------------------- INDEX MAPPINGS\n",
      "{'kwiz': {'mappings': {'properties': {'collection': {'type': 'keyword'},\n",
      "                                      'contents': {'index_options': 'freqs',\n",
      "                                                   'similarity': 'BM25',\n",
      "                                                   'store': True,\n",
      "                                                   'term_vector': 'yes',\n",
      "                                                   'type': 'text'},\n",
      "                                      'doc': {'type': 'keyword'},\n",
      "                                      'sentence_embedding': {'model_id': 'model_kwiz',\n",
      "                                                             'type': 'knn_vector'}}}}}\n",
      "\n",
      "----------------------------------------------------------------------------------- INDEX #DOCs\n",
      "{'count': 23596, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chosen_topic= 77\n",
    "conversation = []\n",
    "topics = {}\n",
    "for topic in test_bed.train_topics:\n",
    "    conv_id = topic['number']\n",
    "    if conv_id not in (1, 2, 4, 7, 15, 17, 18, 22, 23, 24, 25, 27, 30):\n",
    "        continue\n",
    "    previous_query_tokenized = ''\n",
    "    for turn in topic['turn']:\n",
    "        turn_id = turn['number']\n",
    "        utterance = turn['raw_utterance']\n",
    "        updated_utterance = previous_query_tokenized + utterance\n",
    "        previous_query_tokenized += preprocess_text(utterance) + ' '\n",
    "        topic_turn_id = '%d_%d'% (conv_id, turn_id)\n",
    "        \n",
    "    \n",
    "        topics[topic_turn_id] = updated_utterance\n",
    "        if conv_id == chosen_topic :\n",
    "            conversation.append({\"conv_id\" : conv_id, \"turn_id\" : turn_id, \"utterance\" : utterance})\n",
    "\n",
    "\n",
    "for topic in test_bed.test_topics:\n",
    "    conv_id = topic['number']\n",
    "\n",
    "    if conv_id not in (31, 32, 33, 34, 37, 40, 49, 50, 54, 56, 58, 59, 61, 67, 68, 69, 75, 77, 78, 79):\n",
    "        continue\n",
    "    \n",
    "    previous_query_tokenized = ''\n",
    "    for turn in topic['turn']:\n",
    "        turn_id = turn['number']\n",
    "        utterance = turn['raw_utterance']\n",
    "        updated_utterance = previous_query_tokenized + utterance\n",
    "        previous_query_tokenized += preprocess_text(utterance) + ' '\n",
    "        topic_turn_id = '%d_%d'% (conv_id, turn_id)\n",
    "        \n",
    "\n",
    "        topics[topic_turn_id] = updated_utterance\n",
    "        if conv_id == chosen_topic :\n",
    "            conversation.append({\"conv_id\" : conv_id, \"turn_id\" : turn_id, \"utterance\" : utterance})\n",
    "\n",
    "\n",
    "\n",
    "opensearch = osearch.OSsimpleAPI()\n",
    "\n",
    "numdocs = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's the difference between soup and stew?\n",
      "what differ soup stew Is chilli a stew?\n",
      "what differ soup stew chilli stew How about goulash?\n",
      "what differ soup stew chilli stew goulash What are popular ones in France?\n",
      "what differ soup stew chilli stew goulash popular one franc How is cassoulet made?\n",
      "what differ soup stew chilli stew goulash popular one franc cassoulet made Tell me about feijoada and its significance.\n",
      "what differ soup stew chilli stew goulash popular one franc cassoulet made tell feijoada signific How is it similar or different from cassoulet?\n",
      "what differ soup stew chilli stew goulash popular one franc cassoulet made tell feijoada signific similar differ cassoulet Tell about Bigos stew.\n",
      "what differ soup stew chilli stew goulash popular one franc cassoulet made tell feijoada signific similar differ cassoulet tell bigo stew Why is it important?\n",
      "what differ soup stew chilli stew goulash popular one franc cassoulet made tell feijoada signific similar differ cassoulet tell bigo stew import What is the history of Irish stew?\n",
      "  turn                                           query  \\\n",
      "0    1    What's the difference between soup and stew?   \n",
      "1    2                               Is chilli a stew?   \n",
      "2    3                              How about goulash?   \n",
      "3    4                What are popular ones in France?   \n",
      "4    5                          How is cassoulet made?   \n",
      "5    6    Tell me about feijoada and its significance.   \n",
      "6    7  How is it similar or different from cassoulet?   \n",
      "7    8                          Tell about Bigos stew.   \n",
      "8    9                            Why is it important?   \n",
      "9   10              What is the history of Irish stew?   \n",
      "\n",
      "                                      expanded_query  \\\n",
      "0       What's the difference between soup and stew?   \n",
      "1            what differ soup stew Is chilli a stew?   \n",
      "2  what differ soup stew chilli stew How about go...   \n",
      "3  what differ soup stew chilli stew goulash What...   \n",
      "4  what differ soup stew chilli stew goulash popu...   \n",
      "5  what differ soup stew chilli stew goulash popu...   \n",
      "6  what differ soup stew chilli stew goulash popu...   \n",
      "7  what differ soup stew chilli stew goulash popu...   \n",
      "8  what differ soup stew chilli stew goulash popu...   \n",
      "9  what differ soup stew chilli stew goulash popu...   \n",
      "\n",
      "                                        top passages  \\\n",
      "0  [What's the difference between a soup and a st...   \n",
      "1  [Specifically, I've always had some confusion ...   \n",
      "2  [1 Stew is more of a meat and vegetables dish ...   \n",
      "3  [Goulash is a rustic stew or soup made made wi...   \n",
      "4  [Goulash is a rustic stew or soup made with be...   \n",
      "5  [Specifically, I've always had some confusion ...   \n",
      "6  [Goulash is a rustic stew or soup made with be...   \n",
      "7  [Specifically, I've always had some confusion ...   \n",
      "8  [Specifically, I've always had some confusion ...   \n",
      "9  [Specifically, I've always had some confusion ...   \n",
      "\n",
      "                                                 _id  \n",
      "0  [MARCO_3831856, MARCO_3712923, MARCO_3070255, ...  \n",
      "1  [MARCO_3712923, MARCO_4533564, MARCO_4533561, ...  \n",
      "2  [MARCO_4948690, MARCO_1469735, CAR_d0dbb5da9f3...  \n",
      "3  [MARCO_954770, MARCO_1469735, MARCO_4948690, C...  \n",
      "4  [MARCO_8594804, MARCO_954770, MARCO_1469735, C...  \n",
      "5  [MARCO_3712923, MARCO_8594804, MARCO_954770, M...  \n",
      "6  [MARCO_8594804, CAR_f3d89bb386f24d75540a4e5cce...  \n",
      "7  [MARCO_3712923, MARCO_1899971, CAR_f3d89bb386f...  \n",
      "8  [MARCO_3712923, MARCO_8594804, MARCO_1899971, ...  \n",
      "9  [MARCO_3712923, MARCO_1469735, MARCO_1899971, ...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def BM_retrieval(k):\n",
    "    #metrics_df = pd.DataFrame(columns=['turn', 'query', '_id'])\n",
    "    BM25data = []\n",
    "    bm25_doc_ids = []\n",
    "    for element in conversation :\n",
    "        topic = str(chosen_topic)\n",
    "        turn = str(element['turn_id'])\n",
    "        utterance = topic + '_' + turn\n",
    "   \n",
    "        query = topics[utterance]\n",
    "        print(query)\n",
    "        opensearch_results = opensearch.search_body(query, numDocs = k)\n",
    "        best_docs = []\n",
    "        best_passages = []\n",
    "        content_to_id = {}  \n",
    "        for index, row in opensearch_results.iterrows():\n",
    "            doc_id = row['_id']\n",
    "            doc_body = opensearch.get_doc_body(doc_id)\n",
    "            best_passages.append(doc_body)\n",
    "            best_docs.append(doc_id)\n",
    "            content_to_id[doc_body] = doc_id  \n",
    "        bm25_doc_ids.append([content_to_id[doc] for doc in best_passages if doc in content_to_id])\n",
    "   \n",
    "            \n",
    "        BM25data.append({'turn': turn, 'query': element[\"utterance\"], 'expanded_query' : query, 'top passages': best_passages, '_id': best_docs})\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame(BM25data)\n",
    "   \n",
    "    return df\n",
    "\n",
    "bm25_results = BM_retrieval(100)\n",
    "print(bm25_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LMDRetriever\n",
    "class LMDRetriever:\n",
    "    def __init__(self, opensearch, corpus_ids):\n",
    "        self.opensearch = opensearch\n",
    "        self.corpus_ids = corpus_ids\n",
    "        self.corpus_length = 0\n",
    "        self.doc_count = len(corpus_ids)\n",
    "        self.index = self.build_index()\n",
    "        self.collection_frequency = self.build_collection_frequency()\n",
    "        self.mu = self.calculate_mu()\n",
    "    \n",
    "    def calculate_mu(self):\n",
    "        avg_doc_length = self.corpus_length / self.doc_count\n",
    "        return 0.1 * avg_doc_length\n",
    "\n",
    "    def build_index(self):\n",
    "        index = {}\n",
    "        for doc_id in self.corpus_ids:\n",
    "            term_vectors = self.opensearch.doc_term_vectors(doc_id)\n",
    "            if term_vectors:\n",
    "                terms = term_vectors[3]\n",
    "                for term, stats in terms.items():\n",
    "                    if term not in index:\n",
    "                        index[term] = {}\n",
    "                    index[term][doc_id] = stats[0]\n",
    "                    self.corpus_length += stats[0]\n",
    "        return index\n",
    "\n",
    "    def build_collection_frequency(self):\n",
    "        collection_frequency = {}\n",
    "        for doc_id in self.corpus_ids:\n",
    "            term_vectors = self.opensearch.doc_term_vectors(doc_id)\n",
    "            if term_vectors:\n",
    "                terms = term_vectors[3]\n",
    "                for term, stats in terms.items():\n",
    "                    if term not in collection_frequency:\n",
    "                        collection_frequency[term] = 0\n",
    "                    collection_frequency[term] += stats[2]\n",
    "        return collection_frequency\n",
    "\n",
    "    def score(self, query, doc_id):\n",
    "        score = 1.0\n",
    "        term_vectors = self.opensearch.doc_term_vectors(doc_id)\n",
    "        if term_vectors:\n",
    "            terms = term_vectors[3]\n",
    "            doc_length = sum([stats[0] for stats in terms.values()])\n",
    "            for term in query.split():\n",
    "                tf = terms.get(term, [0])[0]\n",
    "                cf = self.collection_frequency.get(term, 0)\n",
    "                p_ml = cf / self.corpus_length\n",
    "                p_lmd = (tf + self.mu * p_ml) / (doc_length + self.mu)\n",
    "                if p_lmd > 0:\n",
    "                    score *= p_lmd\n",
    "        return score\n",
    "\n",
    "    def retrieve(self, query, k):\n",
    "        scores = []\n",
    "        for doc_id in self.corpus_ids:\n",
    "            score = self.score(query, doc_id)\n",
    "            scores.append((doc_id, score))\n",
    "        scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "        return scores[:k]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  turn                                           query  \\\n",
      "0    1    What's the difference between soup and stew?   \n",
      "1    2                               Is chilli a stew?   \n",
      "2    3                              How about goulash?   \n",
      "3    4                What are popular ones in France?   \n",
      "4    5                          How is cassoulet made?   \n",
      "5    6    Tell me about feijoada and its significance.   \n",
      "6    7  How is it similar or different from cassoulet?   \n",
      "7    8                          Tell about Bigos stew.   \n",
      "8    9                            Why is it important?   \n",
      "9   10              What is the history of Irish stew?   \n",
      "\n",
      "                                                 _id  \n",
      "0  [MARCO_16539, MARCO_7312785, MARCO_4009632, MA...  \n",
      "1  [CAR_e0559ce4c6079c402ca8c187105fc3099decb965,...  \n",
      "2  [CAR_e0559ce4c6079c402ca8c187105fc3099decb965,...  \n",
      "3  [CAR_2f71ee8fd2627fe73672114087a52c055ccf1e43,...  \n",
      "4  [CAR_fdb1694659cd24f206e5f5eceec1d2d5444fe72f,...  \n",
      "5  [CAR_3bcb55430dbf72eb2817f6b73d0b657e1e57dc89,...  \n",
      "6  [CAR_3bcb55430dbf72eb2817f6b73d0b657e1e57dc89,...  \n",
      "7  [CAR_3bcb55430dbf72eb2817f6b73d0b657e1e57dc89,...  \n",
      "8  [CAR_3bcb55430dbf72eb2817f6b73d0b657e1e57dc89,...  \n",
      "9  [CAR_3bcb55430dbf72eb2817f6b73d0b657e1e57dc89,...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(bm25_results)\n",
    "\n",
    "#print('-------------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "reranked_df = pd.DataFrame(columns=[\"turn\", \"query\", \"_id\"])\n",
    "\n",
    "for index, row in bm25_results.iterrows():\n",
    "   \n",
    "    bm25_doc_ids = row[\"_id\"] \n",
    "    turn = row[\"turn\"]\n",
    "    query = row[\"expanded_query\"]\n",
    "\n",
    "\n",
    "    lmd_retriever = LMDRetriever(opensearch=opensearch, corpus_ids=bm25_doc_ids)\n",
    "\n",
    "    reranked_results = lmd_retriever.retrieve(query, k=100)\n",
    "\n",
    "  \n",
    "    top_N_passages = [doc_id for doc_id, score in reranked_results]\n",
    "\n",
    "  \n",
    "    new_row = pd.DataFrame({\n",
    "        \"turn\": [turn],\n",
    "        \"query\": [row[\"query\"]],\n",
    "        \"_id\": [top_N_passages]\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "    reranked_df = pd.concat([reranked_df, new_row], ignore_index=True)\n",
    "\n",
    "\n",
    "print(reranked_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25\n",
      "Turn: 77_1\n",
      "P@10: 0.8, Recall: 0.6153846153846154, AP: 0.35366162517942523, NDCG@5: 0.6215431670303851\n",
      "\n",
      "Turn: 77_2\n",
      "P@10: 0.0, Recall: 0.2, AP: 0.002150537634408602, NDCG@5: 0.0\n",
      "\n",
      "Turn: 77_3\n",
      "P@10: 1.0, Recall: 0.7948717948717948, AP: 0.6093518121885131, NDCG@5: 0.91172809177877\n",
      "\n",
      "Turn: 77_4\n",
      "P@10: 0.0, Recall: 0.25, AP: 0.01251605655533558, NDCG@5: 0.0\n",
      "\n",
      "Turn: 77_5\n",
      "P@10: 0.0, Recall: 0.1388888888888889, AP: 0.008396951250587453, NDCG@5: 0.0\n",
      "\n",
      "Turn: 77_6\n",
      "P@10: 0.1, Recall: 0.45, AP: 0.10590742305386128, NDCG@5: 0.09637771110074017\n",
      "\n",
      "Turn: 77_7\n",
      "P@10: 0.1, Recall: 0.5714285714285714, AP: 0.12287022093071924, NDCG@5: 0.15979138559512832\n",
      "\n",
      "Turn: 77_8\n",
      "P@10: 0.0, Recall: 0.25, AP: 0.019106507605008642, NDCG@5: 0.0\n",
      "\n",
      "Turn: 77_9\n",
      "P@10: 0, Recall: 0, AP: 0, NDCG@5: 0\n",
      "\n",
      "Turn: 77_10\n",
      "P@10: 0, Recall: 0, AP: 0, NDCG@5: 0\n",
      "\n",
      "['77_1', '77_2', '77_3', '77_4', '77_5', '77_6', '77_7', '77_8', '77_9', '77_10'] [0.35366162517942523, 0.002150537634408602, 0.6093518121885131, 0.01251605655533558, 0.008396951250587453, 0.10590742305386128, 0.12287022093071924, 0.019106507605008642, 0, 0] [0.6215431670303851, 0.0, 0.91172809177877, 0.0, 0.0, 0.09637771110074017, 0.15979138559512832, 0.0, 0, 0] [0.8, 0.0, 1.0, 0.0, 0.0, 0.1, 0.1, 0.0, 0, 0] [0.6153846153846154, 0.2, 0.7948717948717948, 0.25, 0.1388888888888889, 0.45, 0.5714285714285714, 0.25, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "turns_BM = []\n",
    "BM_ap_values = []\n",
    "BM_ndcg_values = []\n",
    "BM_precision_values = []\n",
    "BM_recall_values = []\n",
    "\n",
    "print(\"BM25\")\n",
    "\n",
    "for index, row in bm25_results.iterrows():\n",
    "    try:\n",
    "    \n",
    "        turn = f\"77_{row['turn']}\"  \n",
    "        query = row['query']\n",
    "        docs = row['_id']  \n",
    "\n",
    "        result_df = pd.DataFrame({\"_id\": docs})\n",
    "\n",
    "        p10, recall, ap, ndcg5 = test_bed.eval(result_df, turn)\n",
    "        turns_BM.append(turn)\n",
    "        BM_ap_values.append(ap)\n",
    "        BM_ndcg_values.append(ndcg5)\n",
    "        BM_precision_values.append(p10)\n",
    "        BM_recall_values.append(recall)\n",
    "\n",
    "\n",
    "        print(f\"Turn: {turn}\")\n",
    "        \n",
    "    \n",
    "        print(f\"P@10: {p10}, Recall: {recall}, AP: {ap}, NDCG@5: {ndcg5}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "  \n",
    "        print(f\"Erreur sur le tour {turn}: {e}\")\n",
    "        break  \n",
    "\n",
    "print(turns_BM,BM_ap_values,BM_ndcg_values,BM_precision_values, BM_recall_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LMD\n",
      "Turn: 77_1\n",
      "P@10: 0.6, Recall: 0.6153846153846154, AP: 0.21890349531082884, NDCG@5: 0.1599902354470432\n",
      "\n",
      "Turn: 77_2\n",
      "P@10: 0.0, Recall: 0.2, AP: 0.003125, NDCG@5: 0.0\n",
      "\n",
      "Turn: 77_3\n",
      "P@10: 0.3, Recall: 0.7948717948717948, AP: 0.25882643244194437, NDCG@5: 0.1674605507391572\n",
      "\n",
      "Turn: 77_4\n",
      "P@10: 0.1, Recall: 0.25, AP: 0.024812485364711395, NDCG@5: 0.14041677439671904\n",
      "\n",
      "Turn: 77_5\n",
      "P@10: 0.0, Recall: 0.1388888888888889, AP: 0.009951371052788918, NDCG@5: 0.0\n",
      "\n",
      "Turn: 77_6\n",
      "P@10: 0.3, Recall: 0.45, AP: 0.12444064502467019, NDCG@5: 0.2209440956511154\n",
      "\n",
      "Turn: 77_7\n",
      "P@10: 0.0, Recall: 0.5714285714285714, AP: 0.10050228563638879, NDCG@5: 0.0\n",
      "\n",
      "Turn: 77_8\n",
      "P@10: 0.0, Recall: 0.25, AP: 0.013531396189702111, NDCG@5: 0.0\n",
      "\n",
      "Turn: 77_9\n",
      "P@10: 0, Recall: 0, AP: 0, NDCG@5: 0\n",
      "\n",
      "Turn: 77_10\n",
      "P@10: 0, Recall: 0, AP: 0, NDCG@5: 0\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'turns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mErreur sur le tour \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mturn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m  \n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28mprint\u001b[39m(turns,LMD_ap_values,LMD_ndcg_values,LMD_precision_values, LMD_recall_values)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'turns' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"LMD\")\n",
    "\n",
    "turns_LMD = []\n",
    "LMD_ap_values = []\n",
    "LMD_ndcg_values = []\n",
    "LMD_precision_values = []\n",
    "LMD_recall_values = []\n",
    "\n",
    "for index, row in reranked_df.iterrows():\n",
    "    try:\n",
    "    \n",
    "        turn = f\"77_{row['turn']}\"  \n",
    "        query = row['query']\n",
    "        docs = row['_id']  \n",
    "\n",
    "        result_df = pd.DataFrame({\"_id\": docs})\n",
    "\n",
    "        p10, recall, ap, ndcg5 = test_bed.eval(result_df, turn)\n",
    "        turns_LMD.append(turn)\n",
    "        LMD_ap_values.append(ap)\n",
    "        LMD_ndcg_values.append(ndcg5)\n",
    "        LMD_precision_values.append(p10)\n",
    "        LMD_recall_values.append(recall)\n",
    "\n",
    "\n",
    "        print(f\"Turn: {turn}\")\n",
    "        \n",
    "    \n",
    "        print(f\"P@10: {p10}, Recall: {recall}, AP: {ap}, NDCG@5: {ndcg5}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "  \n",
    "        print(f\"Erreur sur le tour {turn}: {e}\")\n",
    "        break  \n",
    "\n",
    "print(turns_LMD,LMD_ap_values,LMD_ndcg_values,LMD_precision_values, LMD_recall_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "filtered_turns = []\n",
    "filtered_ap_values = []\n",
    "filtered_ndcg_values = []\n",
    "filtered_precision_values = []\n",
    "filtered_recall_values = []\n",
    "\n",
    "for i in range(len(turns)):\n",
    "\n",
    "    if LMD_ap_values[i] != 0 or LMD_ndcg_values[i] != 0:\n",
    "        filtered_turns.append(turns[i])\n",
    "        filtered_ap_values.append(LMD_ap_values[i])\n",
    "        filtered_ndcg_values.append(LMD_ndcg_values[i])\n",
    "\n",
    " \n",
    "    if LMD_precision_values[i] != 0 or LMD_recall_values[i] != 0:\n",
    "        filtered_precision_values.append(LMD_precision_values[i])\n",
    "        filtered_recall_values.append(LMD_recall_values[i])\n",
    "\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(filtered_turns, filtered_ap_values, marker='o', label='AP', linestyle='-')\n",
    "plt.plot(filtered_turns, filtered_ndcg_values, marker='x', label='NDCG@5', linestyle='-')\n",
    "plt.title(\"Evolution of AP and NCDG5 for each turn\")\n",
    "plt.xlabel(\"Turns\")\n",
    "plt.ylabel(\"Scores\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(filtered_recall_values, filtered_precision_values, marker='o', label='Precision-Recall')\n",
    "plt.title(\"Precision-Recall\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.grid(True)\n",
    "plt.show()\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
